\documentclass{article}


\input{setup/final-report}
\input{setup/author}



\title{Predicting Stock Market with Bayesian Neural Network}


\begin{document}

\maketitle


\begin{abstract}
The randomness of stock market challenge investments to be reliable. Many of approaches has been introduced to find the hidden pattern behind the transitions. However, error estimation with non-parametric method is in the early stage. In this project, we used Bayesian neural network to predict discrete  time-series data with moving window of kernel. The Monte Carlo Markov Chain method is applied to measure the posterior distribution. The purpose is to provide a model-free approach with uncertainty quantification that is essential to the investment strategy. 
\end{abstract}

\section{Introduction}


% Describe the goal of the project briefly, the data set, and the pattern recognition techniques to be used (e.g., data cleaning, data visualization/exploration, feature selection/extraction, classification/regression method, model selection, and error estimation).


% Dataset Bayesian neural network
% Things to write: Feedforward Neural Network with Parallel Tempering MCMC
% Dataset : time-series

Bayesian learning offers an intuitive method to estimate uncertainty and parameter quantification that is crucial for the stock market.  In this project, we will re-implement the Bayesian neural network and introduce hierarchical modeling to predict the stock price before and after COVID-19 prevalence \cite{chandra2021bayesian}. 

% With Bayesian learning first introduced to neural networks recently, it provides better model uncertainty quantification compared to classical neural networks.

%Our goal is to combine the Bayesian neural network with different techniques such as autoregressive integrated moving average (ARIMA) \cite{Rathnayaka2015AHS}. Furthermore, to accelerate the overall prediction time, we can adopt the an automatic differential equation with delay DE.


The impact of COVID-19 spreading on the stock price of a company in a country is predicted via Bayesian neural network with parallel tempering MCMC sampling\cite{chandra2021bayesian, chandra2019langevin} with uncertainty estimation. In \cite{chandra2021bayesian}, the prediction is made by the historical stock prices of a given country, which loses the information from other countries impacted by COVID-19 earlier. Also,
\href{https://twiecki.io/blog/2018/08/13/hierarchical_bayesian_neural_network/}{the hierarchical Bayesian method} provides an intuitive approach for pooling nested data, and allows group information to be shared and formulate a general model. 

\paragraph{Our goal} is to pool the information from the stock markets of four different countries to estimate the stock dynamics of the target country with \textit{Bayesian neural network} and \textit{hierarchical modeling}. The pooled Bayesian neural network will be used as the informative prior of the target market stock. In the end, four in-group Bayesian neural networks will be marginalized via within-group data and combined into a global model. Noted that each framework can achieve its own task, but the information is shared with each group. The hierarchical Bayesian approach can overcome \href{https://www.pnas.org/doi/10.1073/pnas.1611835114#sec-3}{catastrophic forgetting in the neural networks} (old weights get overwritten) by sharing the higher-order representation informed by groups of data, and potentially improve prediction with augmented information.




\section{Methods}



\section{Dataset}

\paragraph{The dataset} contains the closing price per day for 4 stocks in 4 countries (Table \ref{tab:my_label}). These discrete time-series data is processed by normalization ($x_{i}' = \frac{x_{i} - x_{\min}}{x_{\max} - x_{\min}}$). The dataset is labeled by two timeframes: before and during COVID-19. Suppose the closing stock price is $[x_1, \dots, x_N]$ where $N$ is the length of the time series, the purpose is to predict the time series after the first few days of COVID-19 spreading.



The original data set is $x_t = \{x_{1}, ..., x_{Total}\}$, the training input is a matrix with dimension $m \times s$ (where m is the capture window, and $s$ is the number of samples). The sample is produced by shifting the original time series with lag of $2$.  These discrete time-series data is processed by normalization ($x_{i}' = \frac{x_{i} - x_{\min}}{x_{\max} - x_{\min}}$). 

\begin{equation}
\bar{x}_t = 
\underbrace{\begin{bmatrix}
    x_{1+(t-1)T} & \cdots & x_{m+(t-1)T}\\
    x_{3+(t-1)T} & \cdots & x_{2m+3+(t-1)T}\\
    \vdots & \vdots & \vdots 
\end{bmatrix}}_{\text{m(Capture windows)}}
\end{equation}

\begin{equation}
y_t = 
\underbrace{\begin{bmatrix}
    x_{m+(t-1)T + 1} & \cdots & x_{m+(t-1)T+ n}\\
    x_{2m+3+(t-1)T + 1} & \cdots & x_{2m+3+(t-1)T+ n}\\
    \vdots & \vdots & \vdots
\end{bmatrix}}_{\text{n (Prediction Horizons)}}
\end{equation}


\begin{figure}
     \centering
     \begin{subfigure}[b]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{../img/MMM8_train.pdf}
         \caption{Train set (before COVID-19)}
     \end{subfigure}%
     \begin{subfigure}[b]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{../img/MMM8_test.pdf}
         \caption{Test set (before COVID-19)}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{../img/MMM_covid_train.pdf}
         \caption{Train set during COVID-19}
     \end{subfigure}%
     \begin{subfigure}[b]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{../img/MMM_covid_test.pdf}
         \caption{Test set during COVID-19}
     \end{subfigure}
    \caption{Stock markets of a company before and during COVID-19 \cite{chandra2021bayesian}.}
    \label{fig:data-series}
\end{figure}


\subsection{Framework}

The sequential neural network with one hidden layer is used for the regression problem.

The implementation is based on \textit{Haiku}\cite{haiku2020github}, a neural network library with JAX backend.

\subsection{Training}

We used a Metropolis-asjusted Langevin algorithm to approximate the posterior probability density.



\section{Results}



\bibliography{ref}

\end{document}