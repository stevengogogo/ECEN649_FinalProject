\documentclass[a4paper]{article}
\usepackage{savetrees}
\usepackage{geometry}
    \geometry{scale=.8}
\usepackage{setspace}
    \setstretch{1.1}
\usepackage[compact]{titlesec}
\usepackage[colorlinks = true, 
            linkcolor = cyan, 
            urlcolor  = cyan,
            citecolor = cyan]{hyperref}
\usepackage[numbers]{natbib}
\newlength\bibitemsep
\bibliographystyle{ieeetr} 
\usepackage{amsmath}
\usepackage{tabularx}

% Requirement: https://github.com/stevengogogo/ECEN649_FinalProject/files/9907283/Class_Project.1.pdf



\title{Bayesian neural network for forecasting stock price before and after COVID spreading}

\author{%
  Shao-Ting Chiu\thanks{UIN: 433002162 (\texttt{stchiu@tamu.edu})}; 
  Chan-Min Hsu\thanks{UIN: 532008407 (\texttt{chanminhsu@tamu.edu})}
}

\begin{document}

\maketitle


\section{Project Description}

% Describe the goal of the project briefly, the data set, and the pattern recognition techniques to be used (e.g., data cleaning, data visualization/exploration, feature selection/extraction, classification/regression method, model selection, and error estimation).


% Dataset Bayesian neural network
% Things to write: Feedforward Neural Network with Parallel Tempering MCMC
% Dataset : time-series

Bayesian learning offers a new method to estimate the model uncertainty and parameter quantification. With Bayesian learning first introduced to neural networks recently, it provides better model uncertainty quantification compared to classical neural networks. In this project, we will implement a Bayesian neural network to predict the stock price before and after COVID-19 prevailed \cite{chandra2021bayesian}. The detail of framework will be shown below.


\section{Goal}

Our goal is to combine the Bayesian neural network with different techniques such as autoregressive integrated moving average (ARIMA) \cite{Rathnayaka2015AHS}. Furthermore, to accelerate the overall prediction time, we can also adopt the idea of automatic differential equation with delay DE.

\section{Framework}

Parallel tempering MCMC enables replica samplers that can explore multi-modal posterior distributions in parallel \cite{chandra2019langevin, chandra2021bayesian}. Each replica agent swaps at intervals with the Metropolis-Hastings acceptance criterion. Based on \cite{chandra2021bayesian}, 

\section{Dataset}

The dataset contains the closing price per day for 4 stocks in 4 countries (Table \ref{tab:my_label}). These discrete time-series data is processed by normalization ($x_{i}' = \frac{x_{i} - x_{\min}}{x_{\max} - x_{\min}}$). The dataset is labeled by two timeframes: before and during COVID-19. Based on Taken's theorem, 

\footnotetext{\url{https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket/tree/master/code/datasets}}


\cite[ch5]{bishop2006pattern}

\section{Relation to ECEN649}

This project focuses on forecasting time-series data \cite[Ch. 11]{braga2020fundamentals}, and using function-approximation method \cite[Ch. 6]{braga2020fundamentals}. The uncertainty quantification \cite[Ch. 7]{braga2020fundamentals} is one of the major reasons to introduce the Bayesian approach \cite[Ch. 2]{braga2020fundamentals} for predicting the stock market. The Bayesian neural network can be regarded as an ensemble approach \cite[Ch. 3.5]{braga2020fundamentals}. Also, Bayesian approach can achieve model selection (Occam's razor effect of Bayesian) \cite[Ch. 8]{braga2020fundamentals} and prevent overfitting without setting regularization terms \cite[Ch. 6]{braga2020fundamentals}.


\begin{table}[h]
    \centering
    \begin{tabularx}{\textwidth}{cX}
       \textbf{Resources} & \textbf{Description} \\
       \hline
       \href{https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket}{Source code  of \cite{chandra2021bayesian}} & See primary paper\cite{chandra2021bayesian}. This paper applied langevin-gradient parallel tempering from \cite{chandra2019langevin} with stock data under the influences of COVID-19\\\hline
       \href{https://github.com/sydney-machine-learning/parallel-tempering-neural-net}{Source code of \cite{chandra2019langevin}} & See secondary paper\cite{chandra2019langevin} that propose parallel computing of langevin gradient Monte Carlo for Bayesian neural network\\\hline
        \href{https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket/blob/master/code/datasets/raw/DAI.DE.csv}{Raw data}  & The original dataset with opened, closed, highest, lowest prices within a day. 1267 days recorded.  \\\hline
       \href{https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket/blob/master/code/datasets/600118.SS_1_train.txt}{Processed dataset}  & Filtered dataset. In \cite{chandra2021bayesian}, only one feature is used per day.  \\\hline
       \href{https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket/blob/6d24cf25115b6517e3099249bc657674f6b9b98f/code/pt_timeseries_regression.py\#L36-L142}{Bayesian framework} & The implementation is based on \texttt{NumPy}, and the parallel tempering is based on \texttt{multiprocess} package. The computation requires multiprocessing with CPUs.\\
    \end{tabularx}
    \caption{Resources from \cite{chandra2021bayesian}}
    \label{tab:my_label}
\end{table}

\bibliography{ref}

\end{document}