@book{braga2020fundamentals,
  title={Fundamentals of pattern recognition and machine learning},
  author={Braga-Neto, Ulisses},
  year={2020},
  publisher={Springer}
}

@article{chandra2021bayesian,
  title={Bayesian neural networks for stock price forecasting before and during COVID-19 pandemic},
  author={Chandra, Rohitash and He, Yixuan},
  journal={Plos one},
  volume={16},
  number={7},
  pages={e0253217},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA},
  note= {"Primary paper (Data/Method)"}
}

@article{chandra2019langevin,
  title={Langevin-gradient parallel tempering for Bayesian neural learning},
  author={Chandra, Rohitash and Jain, Konark and Deo, Ratneel V and Cripps, Sally},
  journal={Neurocomputing},
  volume={359},
  pages={315--326},
  year={2019},
  publisher={Elsevier},
  note = {"Secondary Paper (Method)"}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M and Nasrabadi, Nasser M},
  volume={4},
  number={4},
  year={2006},
  publisher={Springer}
}

@article{Rathnayaka2015AHS,
  title={A hybrid statistical approach for stock market forecasting based on Artificial Neural Network and ARIMA time series models},
  author={R. M. Kapila Tharanga Rathnayaka and D. M. K. N. Seneviratna and Jianguo Wei and Hasitha Indika Arumawadu},
  journal={2015 International Conference on Behavioral, Economic and Socio-cultural Computing (BESC)},
  year={2015},
  pages={54-60}
}


@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}


@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@software{haiku2020github,
  author = {Tom Hennigan and Trevor Cai and Tamara Norman and Igor Babuschkin},
  title = {{H}aiku: {S}onnet for {JAX}},
  url = {http://github.com/deepmind/dm-haiku},
  version = {0.0.9},
  year = {2020},
}

@article{jospin2022a,
  title = {Hands-on {{Bayesian Neural Networks}} -- a {{Tutorial}} for {{Deep Learning Users}}},
  author = {Jospin, Laurent Valentin and Buntine, Wray and Boussaid, Farid and Laga, Hamid and Bennamoun, Mohammed},
  year = {2022},
  month = may,
  journal = {IEEE Computational Intelligence Magazine},
  volume = {17},
  number = {2},
  eprint = {2007.06823},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  pages = {29--48},
  issn = {1556-603X, 1556-6048},
  doi = {10.1109/MCI.2022.3155327},
  abstract = {Modern deep learning methods constitute incredibly powerful tools to tackle a myriad of challenging problems. However, since deep learning methods operate as black boxes, the uncertainty associated with their predictions is often challenging to quantify. Bayesian statistics offer a formalism to understand and quantify the uncertainty associated with deep neural network predictions. This tutorial provides deep learning practitioners with an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian neural networks, i.e., stochastic artificial neural networks trained using Bayesian methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62-02 (Primary),Computer Science - Machine Learning,G.3,I.2.6,Statistics - Machine Learning},
  file = {/Users/stevenchiu/Zotero/storage/2TCKFZ9X/Jospin et al. - 2022 - Hands-on Bayesian Neural Networks -- a Tutorial fo.pdf}
}


@article{roberts1998optimal,
  title={Optimal scaling of discrete approximations to Langevin diffusions},
  author={Roberts, Gareth O and Rosenthal, Jeffrey S},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={60},
  number={1},
  pages={255--268},
  year={1998},
  publisher={Wiley Online Library}
}

@book{neal1996,
  title = {Bayesian {{Learning}} for {{Neural Networks}}},
  author = {Neal, Radford M.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
  year = {1996},
  series = {Lecture {{Notes}} in {{Statistics}}},
  volume = {118},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-0745-0},
  abstract = {Two features distinguish the Bayesian approach to learning models from data. First, beliefs derived from background knowledge are used to select a prior probability distribution for the model parameters. Second, predictions of future observations are made by integrating the model's predictions with respect to the posterior parameter distribution obtained by updating this prior to take account of the data. For neural network models, both these aspects present di culties | the prior over network parameters has no obvious relation to our prior knowledge, and integration over the posterior is computationally very demanding.},
  isbn = {978-0-387-94724-2 978-1-4612-0745-0},
  langid = {english},
  file = {/Users/stevenchiu/Zotero/storage/SP4CQUUW/Neal - 1996 - Bayesian Learning for Neural Networks.pdf}
}

@incollection{neal2011,
  title = {{{MCMC Using Hamiltonian Dynamics}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Neal, Radford},
  editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year = {2011},
  month = may,
  volume = {20116022},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b10905-6},
  isbn = {978-1-4200-7941-8 978-1-4200-7942-5},
  langid = {english},
  file = {/Users/stevenchiu/Zotero/storage/JJVUK9R4/Neal - 2011 - MCMC Using Hamiltonian Dynamics.pdf}
}

@incollection{takens1981detecting,
  title={Detecting strange attractors in turbulence},
  author={Takens, Floris},
  booktitle={Dynamical systems and turbulence, Warwick 1980},
  pages={366--381},
  year={1981},
  publisher={Springer}
}

@article{durmus2019high,
  title={High-dimensional Bayesian inference via the unadjusted Langevin algorithm},
  author={Durmus, Alain and Moulines, Eric},
  journal={Bernoulli},
  volume={25},
  number={4A},
  pages={2854--2882},
  year={2019},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}


@article{hoffman2014no,
  title={The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  author={Hoffman, Matthew D and Gelman, Andrew and others},
  journal={J. Mach. Learn. Res.},
  volume={15},
  number={1},
  pages={1593--1623},
  year={2014}
}